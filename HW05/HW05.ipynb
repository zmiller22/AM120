{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AM120 HW05\n",
    "## Zachary Miller"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[-4,-1,-3],[1,-4,5],[3,4,3],[-5,-1,2]]);\n",
    "b = np.array([-1,4,-4,-2]).reshape(4,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The solution to $A\\vec{x}=\\vec{b}$ with $A$ and $\\vec{b}$ as given above does not exist. Instead, we will look for a solution that minimizes the norm of the error $\\vec{e}=A\\vec{x}-\\vec{b}$, which is given by $\\vec{e}^T\\vec{e}$. To do this, we take the derivative with respect to $\\vec{x}$ of $\\vec{e}^T\\vec{e}$ and set it to zero. After some calculus, this comes out to be \n",
    "\n",
    "$$2(A^TA\\vec{x}-A^T\\vec{b})=0$$ $$A^TA\\vec{x}=A^T\\vec{b}$$ $$\\vec{x}=(A^TA)^{-1}A^T\\vec{b}$$ \n",
    "\n",
    "Calculating below..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:\n",
      "[[ 0.58732799]\n",
      " [-1.19370936]\n",
      " [-0.22879177]]\n"
     ]
    }
   ],
   "source": [
    "x = np.linalg.inv(A.T@A)@A.T@b\n",
    "print(\"x:\")\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we are asked to calculate the residual $\\vec{r}=A\\vec{x}-\\vec{b}$. Calculating below..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r:\n",
      "[[ 0.53077272]\n",
      " [ 0.21820656]\n",
      " [ 0.30077121]\n",
      " [-0.20051414]]\n"
     ]
    }
   ],
   "source": [
    "r = A@x-b\n",
    "print(\"r:\")\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The residual is non-zero. This makes sense because our system of linear equations we were trying to solve for has more equations than unkowns, and the equations are inconsistent. As a result, there will be no exact solution which is why we found the least squares solution instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r_norm =  0.6782352278863029\n",
      "b_norm =  6.082762530298219\n"
     ]
    }
   ],
   "source": [
    "r_norm = np.linalg.norm(r)\n",
    "b_norm = np.linalg.norm(b)\n",
    "print(\"r_norm = \", r_norm)\n",
    "print(\"b_norm = \", b_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the norm of the residual with the norm of $\\vec{b}$, the norm of the residual is approximately one tenth of the norm of $\\vec{b}$. Whether this residual is big or small will depend on the specific application, but for most applications this would probably be considered a relatively small residual. In general, it is a good idea to compare the norm of the residual with the norm of $\\vec{b}$ since the relative sizes of these two numbers tell you something about the relative \"fit\" of your least squares solution. For example, if you had a really small $||\\vec{b}||$, then even if the residual is also small (but on the same order as $||\\vec{b}||$), it would likely not be considered a good fit since the $||\\vec{b}||$ was small to begin with"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "py_x = np.linalg.lstsq(A,b,rcond=None)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python's solution: \n",
      " [[ 0.58732799]\n",
      " [-1.19370936]\n",
      " [-0.22879177]]\n",
      "My solution: \n",
      " [[ 0.58732799]\n",
      " [-1.19370936]\n",
      " [-0.22879177]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Python's solution: \\n\", py_x)\n",
    "print(\"My solution: \\n\", x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, python's solution and my solution are the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.linalg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[-0.9, 0.7, -0.1],[0.6, 0.3, -0.1]])\n",
    "b = np.array([0.6, 0.8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are given the under-determined system above and told to solve it using the pseudo inverse of $A$, denoted as $A^{\\dagger}$. We can do this by getting the usual $U, V^{T},$ and $\\Sigma$ via standard SVD of $A$. We then take the pseudo inverse of $\\Sigma$, defined as the transpose of $\\Sigma$ with the non-zero diagonal elements of $\\Sigma$ replaced by their inverse, to obtain $\\Sigma^{\\dagger}$. Then, we finally obtain $A^{\\dagger}=V \\Sigma^{\\dagger} U^T$. Doing this below..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pseudo Inverse of A:\n",
      " [[-0.44382247  0.99560176]\n",
      " [ 0.83566573  1.2335066 ]\n",
      " [-0.15593762 -0.32586965]]\n"
     ]
    }
   ],
   "source": [
    "# Get the SVD of A\n",
    "U, Sigma, V_t = np.linalg.svd(A, full_matrices=True)\n",
    "\n",
    "# Make the Sigma array from the list of singular values\n",
    "Sigma_diag = np.diag(Sigma)\n",
    "Sigma_mat = np.zeros(A.shape)\n",
    "Sigma_mat[:Sigma_diag.shape[0],:Sigma_diag.shape[1]] = Sigma_diag\n",
    "\n",
    "# Calculate the pseudo inverse of Sigma_mat\n",
    "Sigma_mat_pinv = np.copy(Sigma_mat)\n",
    "Sigma_mat_pinv[Sigma_mat_pinv != 0] = 1/Sigma_mat_pinv[Sigma_mat_pinv != 0]\n",
    "Sigma_mat_pinv = Sigma_mat_pinv.T\n",
    "\n",
    "# Calculate the pseudo inverse of A using the formula above\n",
    "A_pinv = V_t.T@Sigma_mat_pinv@U.T\n",
    "\n",
    "print(\"Pseudo Inverse of A:\\n\", A_pinv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have $A^{\\dagger}$, we can use it to find $x_1$ by calculating $x_1 = A^{\\dagger}\\vec{b}$. Doing this below and comparing to two different ways of sovling this problem with python..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My solution: \n",
      " [ 0.53018792  1.48820472 -0.3542583 ]\n",
      "\n",
      "Solution using scipy.linalg.pinv: \n",
      " [ 0.53018792  1.48820472 -0.3542583 ]\n",
      "\n",
      "Solution using np.linalg.lstsq: \n",
      " [ 0.53018792  1.48820472 -0.3542583 ]\n"
     ]
    }
   ],
   "source": [
    "# Calculate the equation above\n",
    "x_1 = A_pinv@b\n",
    "\n",
    "# Solve using two other python functions\n",
    "x_2 = scipy.linalg.pinv(A)@b\n",
    "x_3 = np.linalg.lstsq(A,b,rcond=None)[0]\n",
    "\n",
    "print(\"My solution: \\n\", x_1)\n",
    "print(\"\\nSolution using scipy.linalg.pinv: \\n\", x_2)\n",
    "print(\"\\nSolution using np.linalg.lstsq: \\n\", x_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, my answer is the same as using scipy.linalg.pinv or np.linalg.lstsq. scipy.linalg.pinv is just the scipy function for calculating the pseudo inverse, and np.linalg.lstsq is the numpy function for finding the least squares solution to a system of linear equation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
