{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AM120 HW08\n",
    "## Zachary Miller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a i) and ii)\n",
    "We are asked to create a random 140,000 standard normally distributed 2d vectors, and then to calculate their mean, variance, and covariance. We do this using the following equations\n",
    "$$\\bar{\\vec{x}}= \\frac{\\sum_{i}^{n} x_i}{n}$$\n",
    "$$Var(\\vec{x}) = \\frac{\\sum_{i}^{n} (x_i-\\bar{\\vec{x}})^2}{n}$$\n",
    "$$Cov(X) = XX^T/N$$\n",
    "Doing this below..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component Means: [-0.00255699 -0.00362471]\n",
      "Component Variances: [1.00199433 1.0047822 ]\n",
      "Covariance Matrix for 14 Data points:\n",
      "[[ 1.04076445 -0.01401101]\n",
      " [-0.01401101  0.87987283]]\n",
      "Covariance Matrix for 140 Data points:\n",
      "[[ 0.84186369 -0.10970489]\n",
      " [-0.10970489  1.25297686]]\n",
      "Covariance Matrix for 1400 Data points:\n",
      "[[0.98446752 0.03978158]\n",
      " [0.03978158 0.98221125]]\n",
      "Covariance Matrix for 14000 Data points:\n",
      "[[ 1.00984748 -0.00111566]\n",
      " [-0.00111566  1.0014379 ]]\n",
      "Covariance Matrix for 140000 Data points:\n",
      "[[ 1.00200087 -0.00379688]\n",
      " [-0.00379688  1.00479534]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(6968761)\n",
    "N=140000\n",
    "X=np.random.normal(size=(2,N))\n",
    "\n",
    "# Function to calculate the row means\n",
    "def calc_mean(arr):\n",
    "    vec_sum = np.sum(arr, axis=1)\n",
    "    return vec_sum/arr.shape[1]\n",
    "\n",
    "# Function to calculate the row variances\n",
    "def calc_variance(arr):\n",
    "    mean_arr = calc_mean(arr)\n",
    "    var_numer = np.sum(np.square(X-mean_arr.reshape(X.shape[0],-1)),\n",
    "                      axis=1)\n",
    "    var_denom = arr.shape[1]\n",
    "    return var_numer/var_denom\n",
    "\n",
    "# Function to calculate the covariance for a subset of the data points\n",
    "def calc_covariance(arr, subset):\n",
    "    arr_subset = arr[:,:subset]\n",
    "    return np.matmul(arr_subset, arr_subset.T)/subset\n",
    "\n",
    "comp_means = calc_mean(X)\n",
    "comp_vars = calc_variance(X)\n",
    "subsets = [14, 140, 1400, 14000, 140000]\n",
    "    \n",
    "print(f'Component Means: {comp_means}')\n",
    "print(f'Component Variances: {comp_vars}')\n",
    "\n",
    "for subset in subsets:\n",
    "    cov_mat = calc_covariance(X, subset)\n",
    "    print(f'Covariance Matrix for {subset} Data points:\\n{cov_mat}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above component means and variances are very close to 0 and 1. This is to be expected since we drew each coordinate for each point from a standard normal distribution. The progression of the covariance matrices as we include more points also makes sense. Because all of the elements of both components were drawn independently, we would expect the covaraince matrix to be 1 along the diagonal (since each component has varaince 1) and zero everywhere else (since the variables are independent and therefore should have no covariance). For small N, we have more noise in the matrix, but as we increase N that noise gets smaller and we begin to converge towards the expected result. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b\n",
    "We are told that the standard deviation for a cluster of uncorrelated 3d points is 2, 1, and 3 for each dimension, respectivly. Since we are told the data points are not coorelated, we know that the only nonzero terms of the covariance matrix will be the variance terms along the diagonal (which are the square of the standard deviations). Therefore, we can write the covariance matrix as \n",
    "$$C= \\begin{bmatrix}4&0&0\\\\ 0&1&0\\\\ 0&0&25\\end{bmatrix}$$\n",
    "Now we are given the points $\\vec{x_1}=[2,0,1]^T \\text{ and } \\vec{x_2}=[3,-1,4]^T$ and asked to calculate the Mahalanobis distance between these two points. We can do this using the equation $d(\\vec{x_1},\\vec{x_2})=\\sqrt{(\\vec{x_1}-\\vec{x_2})^TC^{-1}(\\vec{x_1}-\\vec{x_2})}$. Calculating below..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mahalonobis Distance between x_1 and x_2 = 1.746424919657298\n"
     ]
    }
   ],
   "source": [
    "# Define vectors and inverse cooelation matrix\n",
    "x_1 = np.array([2,0,1]).reshape(3,1)\n",
    "x_2 = np.array([3,-1,4]).reshape(3,1)\n",
    "C_inv = np.array([[1/4, 0, 0],[0,1,0],[0,0,1/5]])\n",
    "\n",
    "# Calculat the Mahalonobis distance\n",
    "d_mbs = np.sqrt((x_1-x_2).T@C_inv@(x_1-x_2))[0,0]\n",
    "print(f'Mahalonobis Distance between x_1 and x_2 = {d_mbs}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In cases such as this one where the variance of the data in the cluster is different in different directions, it makes sense to use the Mahalanobis distance to measure points distances from the cluster since it takes into account this variablity change along different axis, which euclidean distance does not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1c\n",
    "Now we are told to calculate the covariance matrix for the set of 3d vectors given in the specified data file, and then to use that to calculate the Mahalanobis distance between $\\vec{x_1}$ and $\\vec{x_2}$. Doing this below..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data: (3, 20000)\n",
      "Covariance Matrix:\n",
      " [[1.91843472 0.41467107 0.73318361]\n",
      " [0.41467107 0.85377    0.43108431]\n",
      " [0.73318361 0.43108431 2.28870323]]\n",
      "Inverse Covariance Matrix:\n",
      " [[ 0.63109418 -0.22592535 -0.1596166 ]\n",
      " [-0.22592535  1.37525349 -0.18665829]\n",
      " [-0.1596166  -0.18665829  0.52321932]]\n",
      "\n",
      "Mahalonobis Distance between x_1 and x_2 = 2.707290596091136\n"
     ]
    }
   ],
   "source": [
    "# Load the data and look at its shape\n",
    "data = scipy.io.loadmat('HW08_Mahalanobis.mat')\n",
    "X=data['X']\n",
    "print(f'Shape of data: {X.shape}')\n",
    "\n",
    "# Subtract the mean from the data then calculate and print the covariance matrix\n",
    "X_norm = X-np.mean(X, axis=1).reshape(3,-1)\n",
    "C = (X_norm@X_norm.T)/X_norm.shape[1]\n",
    "print(f'Covariance Matrix:\\n', C)\n",
    "\n",
    "# Get the inverse of the covariance matrix and print \n",
    "C_inv = np.linalg.inv(C)\n",
    "print(f'Inverse Covariance Matrix:\\n', C_inv)\n",
    "\n",
    "# Calculate and print the Mahalonobis distance\n",
    "d_mbs = np.sqrt((x_1-x_2).T@C_inv@(x_1-x_2))[0,0]\n",
    "print(f'\\nMahalonobis Distance between x_1 and x_2 = {d_mbs}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array([[1, 9, 4, 5, 2, 9, 9, 9, 8, 5, 4, 8, 2, 8, 9, 3],\n",
    "            [2, 8, 6, 6, 2, 7, 1, 2, 1, 5, 7, 7, 1, 2, 6, 2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are given the above data and told to cluster using a self organizing map with points 8,9,10,11 as the representative points, a neighborhood kernal of 0.8 for the reference points, a neighborhood kernal of 0.1 for the gridspace points, and a constant learning rate of $\\eta=0.1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
